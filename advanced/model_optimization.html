

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Hardware-aware Optimization API &mdash; hls4ml 1.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_contributors.css?v=f079e67e" />

  
    <link rel="shortcut icon" href="../_static/hls4ml_logo.svg"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=fc837d61"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Loading weights from external BRAM" href="bramfactor.html" />
    <link rel="prev" title="Extension API" href="extension.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html">
            
              <img src="../_static/hls4ml_logo_navbar.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/status.html">Status and Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/setup.html">Setup and Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/reference.html">Citation, Acknowledgments, and Contributors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/command.html">Command Line Interface (deprecated)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/serialization.html">Saving/Loading hls4ml models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../frontend/keras.html">Keras and its quantized variants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/pytorch.html">PyTorch and Brevitas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/qonnx.html">ONNX and QONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../backend/vitis.html">Vivado/Vitis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/accelerator.html">VivadoAccelerator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/oneapi.html">oneAPI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/catapult.html">Catapult</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/quartus.html">Quartus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/sr.html">SymbolicExpression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="profiling.html">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto.html">Automatic precision inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="hgq.html">High Granularity Quantization (HGQ2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="da.html">Distributed Arithmetic</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision.html">Model-wise Precision Inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="fifo_depth.html">FIFO Buffer Depth Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="extension.html">Extension API</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Hardware-aware Optimization API</a></li>
<li class="toctree-l1"><a class="reference internal" href="bramfactor.html">Loading weights from external BRAM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ir/ir.html">Internal representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/modelgraph.html">ModelGraph Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/multimodelgraph.html">MultiModelGraph Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/flows.html">Optimizer Passes and Flows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/attributes.html">Layer attributes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Autogenerated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.backends.html">hls4ml.backends package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.converters.html">hls4ml.converters package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.model.html">hls4ml.model package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.optimization.html">hls4ml.optimization package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.report.html">hls4ml.report package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.utils.html">hls4ml.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.writer.html">hls4ml.writer package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">hls4ml</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Hardware-aware Optimization API</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/fastmachinelearning/hls4ml/blob/main/docs/advanced/model_optimization.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="hardware-aware-optimization-api">
<h1>Hardware-aware Optimization API<a class="headerlink" href="#hardware-aware-optimization-api" title="Link to this heading"></a></h1>
<p>Pruning and weight sharing are effective techniques to reduce model footprint and computational requirements. The hls4ml Optimization API introduces hardware-aware pruning and weight sharing.
By defining custom objectives, the algorithm solves a Knapsack optimization problem aimed at maximizing model performance, while keeping the target resource(s) at a minimum. Out-of-the box objectives include network sparsity, GPU FLOPs, Vivado DSPs, memory utilization etc.</p>
<p>The code block below showcases three use cases of the hls4ml Optimization API - network sparsity (unstructured pruning), GPU FLOPs (structured pruning) and Vivado DSP utilization (pattern pruning). First, we start with unstructured pruning:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.optimizers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Adam</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">CategoricalAccuracy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.losses</span><span class="w"> </span><span class="kn">import</span> <span class="n">CategoricalCrossentropy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.optimization.dsp_aware_pruning.keras</span><span class="w"> </span><span class="kn">import</span> <span class="n">optimize_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.optimization.dsp_aware_pruning.keras.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_model_sparsity</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.optimization.dsp_aware_pruning.attributes</span><span class="w"> </span><span class="kn">import</span> <span class="n">get_attributes_from_keras_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.optimization.dsp_aware_pruning.objectives</span><span class="w"> </span><span class="kn">import</span> <span class="n">ParameterEstimator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.optimization.dsp_aware_pruning.scheduler</span><span class="w"> </span><span class="kn">import</span> <span class="n">PolynomialScheduler</span>
<span class="c1"># Define baseline model and load data</span>
<span class="c1"># X_train, y_train = ...</span>
<span class="c1"># X_val, y_val = ...</span>
<span class="c1"># X_test, y_test = ...</span>
<span class="c1"># baseline_model = ...</span>
<span class="c1"># Evaluate baseline model</span>
<span class="n">y_baseline</span> <span class="o">=</span> <span class="n">baseline_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acc_base</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_baseline</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">sparsity</span><span class="p">,</span> <span class="n">layers</span> <span class="o">=</span> <span class="n">get_model_sparsity</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Baseline Keras accuracy: </span><span class="si">{</span><span class="n">acc_base</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Baseline Keras sparsity, overall: </span><span class="si">{</span><span class="n">sparsity</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Baseline Keras sparsity, per-layer: </span><span class="si">{</span><span class="n">layers</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1"># Defining training parameters</span>
<span class="c1"># Epochs refers to the number of maximum epochs to train a model, after imposing some sparsity</span>
<span class="c1"># If the model is pre-trained, a good rule of thumb is to use between a 1/3 and 1/2 of the number of epochs used to train baseline model</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">metric</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">()</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">CategoricalCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Define the metric to monitor, as well as if its increasing or decreasing</span>
<span class="c1"># This disctinction allows us to optimize both regression and classification models</span>
<span class="c1"># In regression, e.g. minimize validation MSE &amp; for classification e.g. maximize accuracy</span>
<span class="n">metric</span><span class="p">,</span> <span class="n">increasing</span> <span class="o">=</span> <span class="n">CategoricalAccuracy</span><span class="p">(),</span> <span class="kc">True</span>
<span class="c1"># Relative tolerance (rtol) is the the relative loss in metric the optimized model is allowed to incur</span>
<span class="n">rtol</span> <span class="o">=</span> <span class="mf">0.975</span>

<span class="c1"># A scheduler defines how the sparsity is incremented at each step</span>
<span class="c1"># In this case, the maximum sparsity is 50% and it will be applied at a polynomially decreasing rate, for 10 steps</span>
<span class="c1"># If the final sparsity is unspecified, it is set to 100%</span>
<span class="c1"># The optimization algorithm stops either when (i) the relative drop in performance is below threshold or (ii) final sparsity reached</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">PolynomialScheduler</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">final_sparsity</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># Get model attributes</span>
<span class="n">model_attributes</span> <span class="o">=</span> <span class="n">get_attributes_from_keras_model</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">)</span>

<span class="c1"># Optimize model</span>
<span class="c1"># ParameterEstimator is the objective and, in this case, the objective is to minimize the total number of parameters</span>
<span class="n">optimized_model</span> <span class="o">=</span> <span class="n">optimize_model</span><span class="p">(</span>
    <span class="n">baseline_model</span><span class="p">,</span> <span class="n">model_attributes</span><span class="p">,</span> <span class="n">ParameterEstimator</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">increasing</span><span class="p">,</span> <span class="n">rtol</span>
<span class="p">)</span>
<span class="c1"># Evaluate optimized model</span>
<span class="n">y_optimized</span> <span class="o">=</span> <span class="n">optimized_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acc_optimized</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_optimized</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="n">sparsity</span><span class="p">,</span> <span class="n">layers</span> <span class="o">=</span> <span class="n">get_model_sparsity</span><span class="p">(</span><span class="n">optimized_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Optimized Keras accuracy: </span><span class="si">{</span><span class="n">acc_optimized</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Optimized Keras sparsity, overall: </span><span class="si">{</span><span class="n">sparsity</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Opimized Keras sparsity, per-layer: </span><span class="si">{</span><span class="n">layers</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>In a similar manner, it is possible to target GPU FLOPs or Vivado DSPs. However, in that case, sparsity is not equivalent to model sparsity.
Instead, it is the sparsity of the target resource. As an example: Starting with a network utilizing 512 DSPs and a final sparsity of 50%; the optimized network will use 256 DSPs.</p>
<p>To optimize GPU FLOPs, the code is similar to above:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.optimization.dsp_aware_pruning.objectives.gpu_objectives</span><span class="w"> </span><span class="kn">import</span> <span class="n">GPUFLOPEstimator</span>

<span class="c1"># Optimize model</span>
<span class="c1"># Note the change from ParameterEstimator to GPUFLOPEstimator</span>
<span class="n">optimized_model</span> <span class="o">=</span> <span class="n">optimize_model</span><span class="p">(</span>
    <span class="n">baseline_model</span><span class="p">,</span> <span class="n">model_attributes</span><span class="p">,</span> <span class="n">GPUFLOPEstimator</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">increasing</span><span class="p">,</span> <span class="n">rtol</span>
<span class="p">)</span>

<span class="c1"># Evaluate optimized model</span>
<span class="n">y_optimized</span> <span class="o">=</span> <span class="n">optimized_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acc_optimized</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_optimized</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Optimized Keras accuracy: </span><span class="si">{</span><span class="n">acc_optimized</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="c1"># Note the difference in total number of parameters</span>
<span class="c1"># Optimizing GPU FLOPs is equivalent to removing entire structures (filters, neurons) from the network</span>
<span class="nb">print</span><span class="p">(</span><span class="n">baseline_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">optimized_model</span><span class="o">.</span><span class="n">summary</span><span class="p">())</span>
</pre></div>
</div>
<p>Finally, optimizing Vivado DSPs is possible, given a hls4ml config:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.utils.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">config_from_keras_model</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.optimization.dsp_aware_pruning.objectives.vivado_objectives</span><span class="w"> </span><span class="kn">import</span> <span class="n">VivadoDSPEstimator</span>

<span class="c1"># Note the change from optimize_model to optimize_keras_model_for_hls4ml</span>
<span class="c1"># The function optimize_keras_model_for_hls4ml acts as a wrapper for the function, parsing hls4ml config to model attributes</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">hls4ml.optimization</span><span class="w"> </span><span class="kn">import</span> <span class="n">optimize_keras_model_for_hls4ml</span>

<span class="c1"># Create hls4ml config</span>
<span class="n">default_reuse_factor</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">default_precision</span> <span class="o">=</span> <span class="s1">&#39;ac_fixed&lt;16, 6&gt;&#39;</span>
<span class="n">hls_config</span> <span class="o">=</span> <span class="n">config_from_keras_model</span><span class="p">(</span><span class="n">baseline_model</span><span class="p">,</span> <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;name&#39;</span><span class="p">,</span> <span class="n">default_precision</span><span class="o">=</span><span class="n">default_precision</span><span class="p">,</span> <span class="n">default_reuse_factor</span><span class="o">=</span><span class="n">default_reuse_factor</span><span class="p">)</span>
<span class="n">hls_config</span><span class="p">[</span><span class="s1">&#39;IOType&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;io_parallel&#39;</span>
 <span class="n">hls_config</span><span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">][</span><span class="s1">&#39;Strategy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Resource&#39;</span>   <span class="c1"># Strategy must be present for optimisation</span>

<span class="c1"># Optimize model</span>
<span class="c1"># Note the change from ParameterEstimator to VivadoDSPEstimator</span>
<span class="n">optimized_model</span> <span class="o">=</span> <span class="n">optimize_keras_model_for_hls4ml</span><span class="p">(</span>
    <span class="n">baseline_model</span><span class="p">,</span> <span class="n">model_attributes</span><span class="p">,</span> <span class="n">VivadoDSPEstimator</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">metric</span><span class="p">,</span> <span class="n">increasing</span><span class="p">,</span> <span class="n">rtol</span>
<span class="p">)</span>

<span class="c1"># Evaluate optimized model</span>
<span class="n">y_optimized</span> <span class="o">=</span> <span class="n">optimized_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">acc_optimized</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_optimized</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Optimized Keras accuracy: </span><span class="si">{</span><span class="n">acc_optimized</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>There are two more Vivado “optimizers” - VivadoFFEstimator, aimed at reducing register utilization and VivadoMultiObjectiveEstimator, aimed at optimizing BRAM and DSP utilization.
Note, to ensure DSPs are optimized, “unrolled” Dense multiplication must be used before synthesizing HLS, by modifying the config:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">hls_config</span> <span class="o">=</span> <span class="n">config_from_keras_model</span><span class="p">(</span><span class="n">optimized_model</span><span class="p">)</span>
<span class="n">hls_config</span><span class="p">[</span><span class="s1">&#39;Model&#39;</span><span class="p">][</span><span class="s1">&#39;Strategy&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;Unrolled&#39;</span>
<span class="c1"># Any addition hls4ml config, reuse factor etc...</span>
</pre></div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="extension.html" class="btn btn-neutral float-left" title="Extension API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="bramfactor.html" class="btn btn-neutral float-right" title="Loading weights from external BRAM" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Fast Machine Learning Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>