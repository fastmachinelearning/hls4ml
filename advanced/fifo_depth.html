

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>FIFO Buffer Depth Optimization &mdash; hls4ml 1.2.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sphinx_contributors.css?v=f079e67e" />

  
    <link rel="shortcut icon" href="../_static/hls4ml_logo.svg"/>
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=6efca38a"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Extension API" href="extension.html" />
    <link rel="prev" title="Model-wise Precision Inference" href="precision.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #2980B9" >

          
          
          <a href="../index.html">
            
              <img src="../_static/hls4ml_logo_navbar.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intro/introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/status.html">Status and Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/setup.html">Setup and Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/faq.html">Frequently asked questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro/reference.html">Citation, Acknowledgments, and Contributors</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">User Guide</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api/concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/configuration.html">Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/command.html">Command Line Interface (deprecated)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/serialization.html">Saving/Loading hls4ml models</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../frontend/keras.html">Keras and its quantized variants</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/pytorch.html">PyTorch and Brevitas</a></li>
<li class="toctree-l1"><a class="reference internal" href="../frontend/qonnx.html">ONNX and QONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../backend/vitis.html">Vivado/Vitis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/accelerator.html">VivadoAccelerator</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/oneapi.html">oneAPI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/catapult.html">Catapult</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/quartus.html">Quartus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../backend/sr.html">SymbolicExpression</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Advanced Features</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="profiling.html">Profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto.html">Automatic precision inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="hgq.html">High Granularity Quantization (HGQ2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="da.html">Distributed Arithmetic</a></li>
<li class="toctree-l1"><a class="reference internal" href="precision.html">Model-wise Precision Inference</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">FIFO Buffer Depth Optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="extension.html">Extension API</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_optimization.html">Hardware-aware Optimization API</a></li>
<li class="toctree-l1"><a class="reference internal" href="bramfactor.html">Loading weights from external BRAM</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Internals</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ir/ir.html">Internal representation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/modelgraph.html">ModelGraph Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/multimodelgraph.html">MultiModelGraph Class</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/flows.html">Optimizer Passes and Flows</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ir/attributes.html">Layer attributes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Autogenerated API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.backends.html">hls4ml.backends package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.converters.html">hls4ml.converters package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.model.html">hls4ml.model package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.optimization.html">hls4ml.optimization package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.report.html">hls4ml.report package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.utils.html">hls4ml.utils package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../autodoc/hls4ml.writer.html">hls4ml.writer package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #2980B9" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">hls4ml</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">FIFO Buffer Depth Optimization</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/fastmachinelearning/hls4ml/blob/main/docs/advanced/fifo_depth.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="fifo-buffer-depth-optimization">
<h1>FIFO Buffer Depth Optimization<a class="headerlink" href="#fifo-buffer-depth-optimization" title="Link to this heading"></a></h1>
<p>With the <code class="docutils literal notranslate"><span class="pre">io_stream</span></code> IO type, each layer is connected with the subsequent layer through first-in first-out (FIFO) buffers.
The implementation of the FIFO buffers contribute to the overall resource utilization of the design, impacting in particular the BRAM or LUT utilization.
Because the neural networks can have complex architectures generally, it is hard to know a priori the correct depth of each FIFO buffer.
By default <code class="docutils literal notranslate"><span class="pre">hls4ml</span></code> choses the most conservative possible depth for each FIFO buffer, which can result in a an unnecessary over-utilization of resources.</p>
<p>In order to reduce the impact on the resources used for FIFO buffer implementation, an optimization flow has been developed that correctly sizes the depth
of the FIFO buffers by analyzing the RTL co-simulation. This feature is currently available in <code class="docutils literal notranslate"><span class="pre">Vitis</span></code> and <code class="docutils literal notranslate"><span class="pre">Vivado</span></code> backends.</p>
<p>In <code class="docutils literal notranslate"><span class="pre">Vivado</span></code> backend, FIFO buffer resizing is implemented as a <a class="reference internal" href="../autodoc/hls4ml.backends.vivado.passes.html#module-hls4ml.backends.vivado.passes.fifo_depth_optimization" title="hls4ml.backends.vivado.passes.fifo_depth_optimization"><code class="xref py py-class docutils literal notranslate"><span class="pre">fifo_depth_optimization</span></code></a> optimizer pass.
Through RTL simulation with large FIFO buffers (by default set to a depth of 100,000), we estimate the maximum occupation of each FIFO.
Once the maximum depth is determined, the optimizer pass sets the FIFO buffer depth to that value plus 1.</p>
<p>Below we show an example of the use of the FIFO depth optimization. First, we can define a simple neural network in Keras:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.layers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tensorflow.keras.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">Sequential</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc1&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc2&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc3&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;fc4&#39;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>
</pre></div>
</div>
<p>Then, we can convert the model, including the flow:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">hls4ml</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">config_from_keras_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">granularity</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">)</span>
<span class="n">config</span><span class="p">[</span><span class="s1">&#39;Flows&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;vivado:fifo_depth_optimization&#39;</span><span class="p">]</span>
<span class="n">hls4ml</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">get_optimizer</span><span class="p">(</span><span class="s1">&#39;vivado:fifo_depth_optimization&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">profiling_fifo_depth</span><span class="o">=</span><span class="mi">100_000</span><span class="p">)</span>


<span class="n">hls_model</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">convert_from_keras_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                                                       <span class="n">io_type</span><span class="o">=</span><span class="s1">&#39;io_stream&#39;</span><span class="p">,</span>
                                                       <span class="n">hls_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                                                       <span class="n">output_dir</span><span class="o">=</span><span class="s1">&#39;hls4mlprj_fifo_depth_opt&#39;</span><span class="p">,</span>
                                                       <span class="n">part</span><span class="o">=</span><span class="s1">&#39;xc7z020clg400-1&#39;</span><span class="p">,</span>
                                                       <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vivado&#39;</span><span class="p">)</span>

<span class="n">hls_model</span><span class="o">.</span><span class="n">build</span><span class="p">(</span><span class="n">reset</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">csim</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">synth</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">cosim</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>For more details and results, see <a class="reference external" href="https://arxiv.org/abs/2206.11791">H. Borras et al., “Open-source FPGA-ML codesign for the MLPerf Tiny Benchmark” (2022)</a>.</p>
<p>Similarly, the FIFO buffers can be optimized while using the <code class="docutils literal notranslate"><span class="pre">Vitis</span></code> backend with the following changes:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">config</span><span class="p">[</span><span class="s1">&#39;Flows&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;vitis:fifo_depth_optimization&#39;</span><span class="p">]</span>
<span class="n">hls4ml</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">get_optimizer</span><span class="p">(</span><span class="s1">&#39;vitis:fifo_depth_optimization&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">configure</span><span class="p">(</span><span class="n">profiling_fifo_depth</span><span class="o">=</span><span class="mi">100_000</span><span class="p">)</span>

<span class="n">hls_model</span> <span class="o">=</span> <span class="n">hls4ml</span><span class="o">.</span><span class="n">converters</span><span class="o">.</span><span class="n">convert_from_keras_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                                                    <span class="n">io_type</span><span class="o">=</span><span class="s1">&#39;io_stream&#39;</span><span class="p">,</span>
                                                    <span class="n">hls_config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
                                                    <span class="n">output_dir</span><span class="o">=</span><span class="s1">&#39;hls4mlprj_fifo_depth_opt&#39;</span><span class="p">,</span>
                                                    <span class="n">part</span><span class="o">=</span><span class="s1">&#39;xc7z020clg400-1&#39;</span><span class="p">,</span>
                                                    <span class="n">backend</span><span class="o">=</span><span class="s1">&#39;Vitis&#39;</span><span class="p">)</span>
</pre></div>
</div>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="precision.html" class="btn btn-neutral float-left" title="Model-wise Precision Inference" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="extension.html" class="btn btn-neutral float-right" title="Extension API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Fast Machine Learning Lab.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>