from datetime import datetime

# import the library
from pynq import Overlay     # import the overlay
from pynq import allocate    # import for CMA (contingeous memory allocation)
from pynq import DefaultIP   # import the ip connector library for extension
from pynq import Interrupt
from pynq import PL

import axi_master_driver
import asyncio
import numpy as np
import os
import subprocess
import re
import time


class NeuralNetworkOverlay(Overlay):
    def __init__(
        self, bitfile_name, x_shape, y_shape, dtype=np.float32, dtbo=None, download=True, ignore_version=False, device=None
    ):
        super().__init__(bitfile_name, dtbo=None, download=True, ignore_version=False, device=None)
        self.input_buffer = allocate(shape=x_shape, dtype=dtype)
        self.output_buffer = allocate(shape=y_shape, dtype=dtype)


    def calculate_performance(self, N, execution_time):
        rate = N / execution_time if execution_time > 0 else float('inf')
        print(
            f"Processed elements: {N}, Execution time: {execution_time:.4f} seconds, Performance rate: {rate:.2f} inferences/second")
        return rate


    def predict(self, X, debug=False, profile=False, encode=None, decode=None):
        """
        Obtain the predictions of the NN implemented in the FPGA.
        Parameters:
        - X : the input vector. Should be numpy ndarray.
        - dtype : the data type of the elements of the input/output vectors.
                  Note: it should be set depending on the interface of the accelerator; if it uses 'float'
                  types for the 'data' AXI-Stream field, 'np.float32' dtype is the correct one to use.
                  Instead if it uses 'ap_fixed<A,B>', 'np.intA' is the correct one to use (note that A cannot
                  any integer value, but it can assume {..., 8, 16, 32, ...} values. Check `numpy`
                  doc for more info).
                  In this case the encoding/decoding has to be computed by the PS. For example for
                  'ap_fixed<16,6>' type the following 2 functions are the correct one to use for encode/decode
                  'float' -> 'ap_fixed<16,6>':
                  ```
                    def encode(xi):
                        return np.int16(round(xi * 2**10)) # note 2**10 = 2**(A-B)
                    def decode(yi):
                        return yi * 2**-10
                    encode_v = np.vectorize(encode) # to apply them element-wise
                    decode_v = np.vectorize(decode)
                  ```
        - profile : boolean. Set it to `True` to print the performance of the algorithm in term of `inference/s`.
        - encode/decode: function pointers. See `dtype` section for more information.
        - return: an output array based on `np.ndarray` with a shape equal to `y_shape` and a `dtype` equal to
                  the namesake parameter.
        """

        # reset the PL
        PL.reset()
        # set interrupt controller
        my_interrupt = Interrupt("myproject_axi_master_1/interrupt")
        # hls-fpga-machine-learning insert ip
        ip = self.<TOP_WRAPPER_NAME>

        if encode is not None:
            X = encode(X)
        np.copyto(self.input_buffer, X)
        exec_time = ip.transfer(self.input_buffer, self.output_buffer, my_interrupt, profile)
        # exec_time will valid only when the profile is enabled
        if decode is not None:
            self.output_buffer = decode(self.output_buffer)

        if profile:
            performance = self.calculate_performance(len(X), exec_time)
            return self.output_buffer, exec_time, performance
        return self.output_buffer
